{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a248256",
      "metadata": {
        "id": "4a248256"
      },
      "source": [
        "#### 1.\tWhy is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of linear threshold units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ab0282",
      "metadata": {
        "id": "15ab0282"
      },
      "source": [
        "There are several reasons why logistic regression is generally preferred over a classical perceptron:\n",
        "\n",
        "1. Output: Logistic regression produces a probabilistic output, which is more suitable for classification tasks compared to a perceptron that only produces binary outputs. Probabilistic output allows for easier interpretation of the model's output and provides a measure of uncertainty.\n",
        "\n",
        "2. Linearity: Logistic regression can model non-linear decision boundaries through the use of polynomial features or interaction terms. In contrast, a single-layer perceptron can only model linear decision boundaries.\n",
        "\n",
        "3. Convergence: Logistic regression converges faster and is less sensitive to outliers compared to a perceptron. Perceptron training can diverge if the data is not linearly separable.\n",
        "\n",
        "To tweak a perceptron to make it equivalent to a logistic regression classifier, you can:\n",
        "\n",
        "1. Replace the step function in the perceptron with a logistic function to produce probabilistic outputs.\n",
        "\n",
        "2. Modify the loss function used in the perceptron training algorithm. Instead of using the perceptron loss function, which only considers misclassified examples, you can use a log-loss function, which takes into account the predicted probabilities.\n",
        "\n",
        "3. Use a multilayer perceptron (MLP) architecture, which allows for the modeling of non-linear decision boundaries through the use of hidden layers and activation functions. The MLP can be trained using backpropagation with a log-loss function, making it equivalent to logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5c5f184",
      "metadata": {
        "id": "f5c5f184"
      },
      "source": [
        "#### 2.\tWhy was the logistic activation function a key ingredient in training the first MLPs?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1df49fc4",
      "metadata": {
        "id": "1df49fc4"
      },
      "source": [
        "the logistic activation function, also known as the sigmoid function, was a key ingredient in training the first Multi-Layer Perceptrons (MLPs) for these main reasons:\n",
        "\n",
        "1) Non-linearity, 2) Gradient calculation, 3) Output range and 4) Smoothness"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf7aaa4",
      "metadata": {
        "id": "edf7aaa4"
      },
      "source": [
        "#### 3.\tName three popular activation functions. Can you draw them?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b4e4a6",
      "metadata": {
        "id": "a8b4e4a6"
      },
      "source": [
        "the three popular activation Functions are:\n",
        "1) Sigmoid\n",
        "2) ReLu\n",
        "3) Hyperbolic Tangent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ffcfa2",
      "metadata": {
        "id": "d9ffcfa2",
        "outputId": "34d71647-9ced-4043-e1ec-30f0d231b5b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Create an array of x values\n",
        "x = np.linspace(-6, 6, 100)\n",
        "\n",
        "# Compute the y values for each activation function\n",
        "y_sigmoid = sigmoid(x)\n",
        "y_relu = relu(x)\n",
        "y_tanh = tanh(x)\n",
        "\n",
        "# Plot the activation functions\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x, y_sigmoid, label='Sigmoid')\n",
        "plt.plot(x, y_relu, label='ReLU')\n",
        "plt.plot(x, y_tanh, label='Tanh')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.title('Activation Functions')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3735837",
      "metadata": {
        "id": "f3735837"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebb65ba",
      "metadata": {
        "id": "0ebb65ba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "746cb7cc",
      "metadata": {
        "id": "746cb7cc"
      },
      "source": [
        "#### 4.\tSuppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
        "- What is the shape of the input matrix X?\n",
        "- What about the shape of the hidden layer’s weight vector Wh, and the shape of its bias vector bh?\n",
        "- What is the shape of the output layer’s weight vector Wo, and its bias vector bo?\n",
        "- What is the shape of the network’s output matrix Y?\n",
        "- Write the equation that computes the network’s output matrix Y as a function of X, Wh, bh, Wo and bo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94944322",
      "metadata": {
        "id": "94944322"
      },
      "source": [
        "The MLP has:\n",
        "\n",
        "Input layer with 10 passthrough neurons\n",
        "Hidden layer with 50 artificial neurons using the ReLU activation function\n",
        "Output layer with 3 artificial neurons using the ReLU activation function\n",
        "Based on this architecture, we can answer the following questions:\n",
        "\n",
        "The shape of the input matrix X would be (m, 10), where m is the number of instances in the input data. Each instance has 10 features corresponding to the 10 passthrough neurons.\n",
        "\n",
        "The shape of the hidden layer's weight matrix Wh would be (10, 50), where 10 is the number of passthrough neurons in the input layer, and 50 is the number of artificial neurons in the hidden layer. The shape of the bias vector bh would be (50,), which has one bias term for each artificial neuron in the hidden layer.\n",
        "\n",
        "The shape of the output layer's weight matrix Wo would be (50, 3), where 50 is the number of artificial neurons in the hidden layer, and 3 is the number of artificial neurons in the output layer. The shape of the bias vector bo would be (3,), which has one bias term for each artificial neuron in the output layer.\n",
        "\n",
        "The shape of the network's output matrix Y would be (m, 3), where m is the number of instances in the input data, and 3 is the number of artificial neurons in the output layer.\n",
        "\n",
        "The equation that computes the network's output matrix Y as a function of X, Wh, bh, Wo, and bo is:\n",
        "\n",
        "where dot() is the dot product operation, np.maximum() is the ReLU activation function, and Y is the output matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332cbd41",
      "metadata": {
        "id": "332cbd41"
      },
      "source": [
        "#### 5.\tHow many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, using what activation function?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dbb704",
      "metadata": {
        "id": "b6dbb704"
      },
      "source": [
        "To classify emails as spam or ham, a single neuron in the output layer is sufficient. The output of this neuron can be interpreted as the probability of the email being spam. By applying a threshold to this probability, such as 0.5, the email can be classified as spam if the probability exceeds the threshold, and as ham otherwise. In this binary classification scenario, the sigmoid function is commonly used as the activation function in the output layer. The sigmoid function outputs a value between 0 and 1, representing the probability of the email belonging to the positive class.\n",
        "\n",
        "On the other hand, for the MNIST dataset, which involves the classification of handwritten digits from 0 to 9, the output layer requires 10 neurons, one for each possible digit. In multi-class classification problems like this, the activation function employed in the output layer is the softmax function. The softmax function generates a probability distribution across the 10 classes, where the output of each neuron corresponds to the probability of the input belonging to a specific class."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e479268",
      "metadata": {
        "id": "4e479268"
      },
      "source": [
        "#### 6.\tWhat is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37671014",
      "metadata": {
        "id": "37671014"
      },
      "source": [
        "Backpropagation is a supervised learning algorithm used for training neural networks through gradient descent optimization. It aims to minimize the discrepancy between the network's predicted output and the actual output by adjusting the network's weights and biases. Backpropagation involves two main phases: the forward pass and the backward pass.\n",
        "\n",
        "During the forward pass, the input is fed through the network layer by layer, computing the output at each layer. This is done by taking the weighted sum of the inputs and applying a non-linear activation function. The output of the final layer is then compared to the true output, resulting in a loss value.\n",
        "\n",
        "In the backward pass, the gradient of the loss function with respect to each weight and bias is computed using the chain rule of differentiation. This process starts from the final layer and moves backward through the network. The gradients are used to update the weights and biases in the opposite direction of the gradient, with the learning rate determining the step size of the update. This iterative process is repeated until the network's performance reaches a satisfactory level.\n",
        "\n",
        "Reverse-mode autodiff, or backpropagation through time, is a more general algorithm used to compute gradients in computational graphs. While backpropagation is a specific implementation of reverse-mode autodiff for neural networks, the underlying principles are the same. Reverse-mode autodiff decomposes the computation graph of a function into elementary operations and recursively applies the chain rule of differentiation from the output to the inputs. This algorithm is efficient for functions with numerous inputs and few outputs, making it suitable for neural networks. In contrast, numerical methods like finite differences become computationally impractical when dealing with a large number of inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71bd58a",
      "metadata": {
        "id": "f71bd58a"
      },
      "source": [
        "#### 7.\tCan you list all the hyperparameters you can tweak in an MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b5e5d56",
      "metadata": {
        "id": "7b5e5d56"
      },
      "source": [
        "In a Multi-Layer Perceptron (MLP), several hyperparameters can be adjusted to influence the model's performance. Here are some key hyperparameters that can be tweaked in an MLP:\n",
        "\n",
        "1. Number of Hidden Layers: The number of hidden layers determines the depth of the network and its ability to capture complex patterns in the data.\n",
        "\n",
        "2. Number of Neurons per Hidden Layer: The number of neurons in each hidden layer controls the capacity and representational power of the network. Increasing the number of neurons can allow the model to learn more intricate relationships but may also lead to overfitting.\n",
        "\n",
        "3. Activation Functions: The choice of activation function for each layer affects the non-linearity and expressive power of the network. Common choices include sigmoid, ReLU, and tanh.\n",
        "\n",
        "4. Learning Rate: The learning rate determines the step size during weight updates in gradient descent. A high learning rate may cause the model to overshoot the optimal solution, while a low learning rate may slow down convergence.\n",
        "\n",
        "5. Regularization: Regularization techniques, such as L1 or L2 regularization, can be applied to prevent overfitting by adding a penalty term to the loss function.\n",
        "\n",
        "6. Dropout: Dropout is a regularization technique that randomly sets a fraction of the neurons to zero during training, reducing interdependencies and preventing overfitting.\n",
        "\n",
        "7. Batch Size: The batch size determines the number of samples processed before weight updates. A larger batch size may provide a more stable estimate of the gradient but can lead to slower convergence.\n",
        "\n",
        "8. Number of Training Iterations: The number of iterations or epochs controls the number of times the entire training dataset is processed during training. Increasing the number of iterations allows the model to learn more from the data, but excessive iterations can lead to overfitting.\n",
        "\n",
        "If the MLP overfits the training data, meaning it performs well on the training data but poorly on new, unseen data, several adjustments can be made to mitigate the issue:\n",
        "\n",
        "1. Reduce Model Complexity: Decrease the number of hidden layers or neurons in each layer to reduce the model's capacity and prevent overfitting.\n",
        "\n",
        "2. Increase Regularization: Strengthen regularization techniques such as L1 or L2 regularization to penalize large weights and encourage simpler models.\n",
        "\n",
        "3. Apply Dropout: Introduce dropout layers to randomly deactivate neurons during training, which can prevent the model from relying too heavily on specific features.\n",
        "\n",
        "4. Augment Training Data: Increase the size and diversity of the training data by applying techniques such as data augmentation, which can help the model generalize better.\n",
        "\n",
        "5. Early Stopping: Monitor the model's performance on a validation set during training and stop training when the validation error starts to increase, indicating overfitting.\n",
        "\n",
        "6. Adjust Learning Rate: Decrease the learning rate to slow down weight updates and allow the model to converge more gradually.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d16db75",
      "metadata": {
        "id": "0d16db75"
      },
      "source": [
        "#### 8.\tTrain a deep MLP on the MNIST dataset and see if you can get over 98% precision. Try adding all the bells and whistles (i.e., save checkpoints, restore the last checkpoint in case of an interruption, add summaries, plot learning curves using TensorBoard, and so on)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "600e9098",
      "metadata": {
        "id": "600e9098"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e7f8390",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e7f8390",
        "outputId": "dffd336c-50a3-4bff-aab6-ed6d1a194995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "230652a2",
      "metadata": {
        "id": "230652a2"
      },
      "outputs": [],
      "source": [
        "# Pre-processing the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = keras.utils.to_categorical(train_labels)\n",
        "test_labels = keras.utils.to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f9b1c855",
      "metadata": {
        "id": "f9b1c855"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e0be519",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e0be519",
        "outputId": "1a8e56e4-4180-4e14-8e6a-f0ff02486f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 15s 4ms/step - loss: 0.3603 - accuracy: 0.8951 - val_loss: 0.1670 - val_accuracy: 0.9513\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1904 - accuracy: 0.9431 - val_loss: 0.1230 - val_accuracy: 0.9630\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1528 - accuracy: 0.9535 - val_loss: 0.1103 - val_accuracy: 0.9649\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1334 - accuracy: 0.9604 - val_loss: 0.0986 - val_accuracy: 0.9705\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1168 - accuracy: 0.9636 - val_loss: 0.0908 - val_accuracy: 0.9713\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1083 - accuracy: 0.9664 - val_loss: 0.0877 - val_accuracy: 0.9727\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0991 - accuracy: 0.9693 - val_loss: 0.0884 - val_accuracy: 0.9728\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0929 - accuracy: 0.9706 - val_loss: 0.0845 - val_accuracy: 0.9741\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0886 - accuracy: 0.9715 - val_loss: 0.0848 - val_accuracy: 0.9752\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0825 - accuracy: 0.9741 - val_loss: 0.0819 - val_accuracy: 0.9754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee5c06ee60>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "245206e5",
      "metadata": {
        "id": "245206e5"
      },
      "outputs": [],
      "source": [
        "# Save checkpoints\n",
        "checkpoint_path = \"model_checkpoint/cp.ckpt\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "031c4178",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "031c4178",
        "outputId": "b72e23fd-6fe8-4977-c28c-c076b007baa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9732\n",
            "Epoch 1: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0827 - accuracy: 0.9732 - val_loss: 0.0813 - val_accuracy: 0.9762\n",
            "Epoch 2/10\n",
            "1858/1875 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9766\n",
            "Epoch 2: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9765 - val_loss: 0.0835 - val_accuracy: 0.9749\n",
            "Epoch 3/10\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9764\n",
            "Epoch 3: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0729 - accuracy: 0.9764 - val_loss: 0.0845 - val_accuracy: 0.9758\n",
            "Epoch 4/10\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9770\n",
            "Epoch 4: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.0873 - val_accuracy: 0.9751\n",
            "Epoch 5/10\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 0.9777\n",
            "Epoch 5: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.0864 - val_accuracy: 0.9749\n",
            "Epoch 6/10\n",
            "1858/1875 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9780\n",
            "Epoch 6: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0663 - accuracy: 0.9781 - val_loss: 0.0851 - val_accuracy: 0.9750\n",
            "Epoch 7/10\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9787\n",
            "Epoch 7: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0636 - accuracy: 0.9786 - val_loss: 0.0867 - val_accuracy: 0.9754\n",
            "Epoch 8/10\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9787\n",
            "Epoch 8: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0630 - accuracy: 0.9787 - val_loss: 0.0816 - val_accuracy: 0.9767\n",
            "Epoch 9/10\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9791\n",
            "Epoch 9: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0617 - accuracy: 0.9790 - val_loss: 0.0906 - val_accuracy: 0.9759\n",
            "Epoch 10/10\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9802\n",
            "Epoch 10: saving model to model_checkpoint/cp.ckpt\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0595 - accuracy: 0.9803 - val_loss: 0.0921 - val_accuracy: 0.9745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee5bf469b0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Train the model with checkpointing\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels), callbacks=[cp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ebea0a8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebea0a8d",
        "outputId": "c9a55b00-2d51-4cb2-923c-162e9a867fae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fee5bda0700>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Restore the last checkpoint\n",
        "latest_checkpoint = tf.train.latest_checkpoint(\"model_checkpoint/\")\n",
        "model.load_weights(latest_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2aba133d",
      "metadata": {
        "id": "2aba133d"
      },
      "outputs": [],
      "source": [
        "# Add summaries\n",
        "log_dir = \"logs/fit/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b436e22d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b436e22d",
        "outputId": "231c9d02-537c-47f4-aa4a-c2d7db4c0809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.0888 - val_accuracy: 0.9760\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.0909 - val_accuracy: 0.9759\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0549 - accuracy: 0.9813 - val_loss: 0.0972 - val_accuracy: 0.9749\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.0966 - val_accuracy: 0.9747\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.0967 - val_accuracy: 0.9737\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.0984 - val_accuracy: 0.9735\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0510 - accuracy: 0.9826 - val_loss: 0.0934 - val_accuracy: 0.9757\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.0957 - val_accuracy: 0.9762\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 0.0949 - val_accuracy: 0.9761\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0470 - accuracy: 0.9837 - val_loss: 0.1048 - val_accuracy: 0.9751\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee5bdbe5c0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels), callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kusqTuDx3W8e"
      },
      "id": "kusqTuDx3W8e",
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}